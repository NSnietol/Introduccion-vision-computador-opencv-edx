En el vídeo anterior explicamos qué es la visión por computador.
En éste
nos vamos a centrar en los principales problemas a los que hay que enfrentarse
cuando hay que diseñar una aplicación que utiliza esta tecnología.
Una vez vista la utilidad de la visión por computador cabe preguntarnos
¿cómo es de fácil desarrollar algoritmos que se basen en el análisis de imágenes?
La respuesta es que es más complicado de lo que parece.
Para las personas el ver resulta una operación fácil, no costosa,
pero eso no quiere decir que no sea compleja
como ya hemos visto en la transparencia anterior.
La visión es un proceso que se realiza en el subconsciente
con lo cual no sabemos los pasos que realizamos para llevarla a cabo.
Por tanto
tampoco sabemos qué pasos deben de dar los computadores a la hora de analizar una imagen.
En el caso de los ordenadores
tenemos una complicación adicional,
y es que realmente los computadores no captan imágenes como las que nosotros vemos,
sino que para ellos constituye una matriz de números
y nuestras aplicaciones
tendrán que traducir esos números en objetos.
En el caso de aplicaciones industriales, donde el ambiente está controlado,
esta tarea es más fácil que en el caso de aplicaciones en exteriores o en nuestra propia casa,
donde existen muchas variables que no podemos determinar o fijar
por lo que la solución de las tareas se va a complicar bastante.
¿A qué nos vamos a enfrentar? o ¿qué problemas tenemos que solventar?
Son varios.
Por un lado los objetos van a presentar un conjunto de apariencias muy distintas en nuestra imagen
ya que dependerá, por ejemplo, del punto de vista
que lo hará aparecer rotados,
trasladados a una zona de la imagen o a otra,
o más o menos grandes.
Y a pesar de esos cambios nuestro algoritmo tiene que saber que se trata del
mismo tipo de objeto.
Además,
podemos tener el caso de que el objeto que estamos buscando no tenga una forma rígida,
por ejemplo un animal,
por lo que presenta cambios debidos al movimiento.
Otro factor muy importante es la iluminación,
que puede no ser constante,
y que no sólo va a producir que las imágenes se vean más claras u oscuras,
sino que además
nos producirán sombras, modificará el contraste entre diversas zonas, etcétera.
En una aplicación normal
el objeto que estamos buscando no va a ser el único que existe en la imagen.
La presencia de otros objetos puede producir oclusiones
con lo cual lo que estamos buscando no lo veremos globalmente
sino sólo alguna de sus partes.
Además se nos complica la búsqueda
ya que tenemos muchos posibles casos donde encontrarlo.
En algunas aplicaciones es difícil definir de forma explícita qué es lo que define a los objetos.
Pensemos un sistema de seguridad
que quiere detectar personas donde por la postura, la ropa, la iluminación, etcétera,
no es fácil definir de forma concreta
qué características queremos buscar en la imagen
para determinar que una persona está presente o no.
O el ejemplo tradicional
de qué es lo que define una silla
ya que pueden tener formas, colores,
o estar hecha de materiales diversos.
A todo ello hay que añadir que, normalmente, existe una restricción temporal muy exigente.
No podemos dar resultados dos minutos o un segundo después de haber capturado la imagen,
sino que tenemos unas pocas decenas de milisegundos.
Y en ese poco tiempo
tenemos que examinar decenas de miles de posibilidades en cada imagen,
con lo cual, si no solo algoritmo funciona al 99,9% de acierto
tendremos varias decenas de errores por cada imagen.
Estos errores serán los falsos positivos, es decir, cuando afirmemos que los objetos buscados están presentes en la imagen
y no sea así.
Y en caso contrario, los falsos negativos,
que es cuando los perdemos.
A pesar de lo anterior, me gustaría decir que son precisamente estas dificultades
las que hacen que implementar un algoritmo de visión por computador sea una tarea apasionante
y ese es el motivo por el cual hemos querido hacer este curso,
para que cada vez más personas se animen a realizar sus propias aplicaciones
de análisis de imágenes.